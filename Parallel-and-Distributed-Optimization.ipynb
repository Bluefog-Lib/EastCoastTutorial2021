{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Parallel and Distributed Optimization\n",
    "\n",
    "This notebook provides concise BlueFog demos to concepts or algorithms introduced in the tutorial. \n",
    "\n",
    "\n",
    "### 1.1 Finite-sum optimizaiton example: distributed least square\n",
    "\n",
    "Suppose $m$ computing nodes collaborate to solve the following problem:\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{x\\in \\mathbb{R}^d}\\ \\sum_{i=1}^n h_i(x) \\quad \\mbox{where} \\quad h_i(x) = \\frac{1}{2}\\|A_i x - b_i\\|^2 \\hspace{1cm} \\mbox{(Opt-Problem)}\n",
    "\\end{align*}\n",
    "\n",
    "where $h_i(x): \\mathbb{R}^d \\to \\mathbb{R}$ is a local cost function held by node $i$ and $\\{A_i, b_i\\}$ are local data. Each node $i$ can evaluate its own data and gradient, but it has to communicate to achieve information from the other node. We let $x^\\star$ denote the global solution to the above problem\n",
    "\n",
    "### 1.2 All-reduce\n",
    "\n",
    "BlueFog supports the Ring-Allreduce operation as follows: \n",
    "```\n",
    "x_bar = bf.allreduce(x_local)\n",
    "```\n",
    "\n",
    "In the following code, we activate 8 computing nodes (CPUs) and label them as $0,1,\\cdots,7$. We target to let all nodes collaborate to compute the global average of their labels $(\\sum_{i=0}^7 i)/8 = 3.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T05:20:53.953031Z",
     "start_time": "2021-03-30T05:20:53.949476Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting allreduce.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile allreduce.py\n",
    " \n",
    "import bluefog.torch as bf\n",
    "import torch\n",
    "\n",
    "bf.init()\n",
    "x_local = torch.ones(1) * bf.rank()\n",
    "x_bar = bf.allreduce(x_local)\n",
    "print('Node {} achieved the global average {}'.format(bf.rank(), x_bar[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T05:20:55.825361Z",
     "start_time": "2021-03-30T05:20:54.582649Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 achieved the global average 1.5\r\n",
      "Node 1 achieved the global average 1.5\r\n",
      "Node 2 achieved the global average 1.5\r\n",
      "Node 3 achieved the global average 1.5\r\n"
     ]
    }
   ],
   "source": [
    "! bfrun -np 4 python allreduce.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Distributed Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distributed gradient descent is $x^{k+1} = x^k - \\frac{\\alpha}{n}\\sum_{i=1}^n \\nabla h_i(x^k)$. This process can be implemented as\n",
    "\n",
    "```python\n",
    "# core distributed gradient descent snippet \n",
    "grad = A.T.mm(A.mm(x) - b)\n",
    "next_x = x - alpha * bf.allreduce(grad)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T05:20:56.918844Z",
     "start_time": "2021-03-30T05:20:56.913919Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting DistributedGD.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile DistributedGD.py\n",
    " \n",
    "import bluefog.torch as bf\n",
    "import torch\n",
    "\n",
    "bf.init()\n",
    "# Make sure different agent has different random seed.\n",
    "torch.manual_seed(12345 * bf.rank())\n",
    "\n",
    "def generate_data(m, d):\n",
    "    A = torch.randn(m, d).to(torch.double)\n",
    "    ns = 0.1*torch.randn(m, 1).to(torch.double)\n",
    "    x_o = torch.rand(d,1).to(torch.double)\n",
    "    b = A.mm(x_o) + ns\n",
    "    \n",
    "    return A, b\n",
    "\n",
    "def check_opt_cond(x, A, b):\n",
    "    \n",
    "    grad_local = A.t().mm(A.mm(x) - b)\n",
    "    grad = bf.allreduce(grad_local, name='gradient')  # global gradient\n",
    "    \n",
    "    # the norm of global gradient is expected to be 0 (optimality condition)\n",
    "    global_grad_norm = torch.norm(grad, p=2)\n",
    "    print(\"[Distributed Grad Descent] Rank {}: global gradient norm: {}\".format(bf.rank(), global_grad_norm))\n",
    "        \n",
    "    return\n",
    "    \n",
    "\n",
    "def distributed_grad_descent(A, b, maxite=5000, alpha=1e-1):\n",
    "\n",
    "    m, d = A.shape\n",
    "    \n",
    "    x_opt = torch.zeros(d, 1, dtype=torch.double)\n",
    "\n",
    "    for _ in range(maxite):\n",
    "        # calculate local gradient \n",
    "        grad_local = A.t().mm(A.mm(x_opt) - b)\n",
    "        \n",
    "        # global gradient\n",
    "        grad = bf.allreduce(grad_local, name='gradient')\n",
    "\n",
    "        # distributed gradient descent\n",
    "        x_opt = x_opt - alpha*grad\n",
    "\n",
    "    check_opt_cond(x_opt, A, b)\n",
    "    \n",
    "    return x_opt\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    m, d = 20, 5 # dimension of A\n",
    "    A, b = generate_data(m, d)\n",
    "    x_opt = distributed_grad_descent(A, b, maxite=200, alpha=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $x^k\\to x^\\star$, it holds that $\\sum_{i=1}^m \\nabla h_i(x^k) \\to 0$. We can use $\\|\\sum_{i=1}^m \\nabla h_i(x)\\|$ as a metric to gauge whether distributed gradient descent converge or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T05:20:59.456793Z",
     "start_time": "2021-03-30T05:20:57.890226Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Distributed Grad Descent] Rank 1: global gradient norm: 1.02174145247192e-12\r\n",
      "[Distributed Grad Descent] Rank 2: global gradient norm: 1.02174145247192e-12\r\n",
      "[Distributed Grad Descent] Rank 3: global gradient norm: 1.02174145247192e-12\r\n",
      "[Distributed Grad Descent] Rank 0: global gradient norm: 1.02174145247192e-12\r\n"
     ]
    }
   ],
   "source": [
    "! bfrun -np 4 python DistributedGD.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Primal Decomposition\n",
    "\n",
    "We consider the following linearly-constrained resource sharing problem:\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{\\{x_i\\}, y}&\\quad \\|y\\|_1 + \\frac{1}{2}\\sum_{i=1}^n \\|A_i x_i - b_i\\|^2 \\\\\n",
    "\\mathrm{s.t.} &\\quad\\sum_{i=1}^n B_i x_i = y\n",
    "\\end{align*}\n",
    "\n",
    "where $x_i \\in \\mathbb{R}^d$, $A_i \\in \\mathbb{R}^{m\\times d}$, and $B_i \\in \\mathbb{R}^{d\\times d}$. For simplicity, we assume each $B_i$ is a invertible matrix. Each node $i$ has local data $\\{A_i, B_i, b_i\\}$. To solve the above problem in a distributed manner, we introduce $y_i = B_i x_i$ so that $y=\\sum_{i=1}^n y_i$. Since $B_i$ is invertible, we have $x_i = B_i^{-1} y_i$. Substituting these facts into the above problem, we achieve\n",
    "\n",
    "\\begin{align*}\n",
    "\\min_{\\{y_i\\}}&\\quad \\|y_1 + \\cdots + y_n\\|_1 + \\frac{1}{2}\\sum_{i=1}^n \\|A_i B_i^{-1} y_i - b_i\\|^2 \n",
    "\\end{align*}\n",
    "\n",
    "which can be solved in the following distributed manner. For notation simplicity, we let $C_i = A_i B_i^{-1}$ and $g(y_1,\\cdots, y_n) = \\|y_1 + \\cdots + y_n\\|_1$. Following proximal gradient descent, we have \n",
    "\n",
    "\\begin{align*}\n",
    "z_i^{k+1} &= y_i^k - \\alpha C_i^T(C_i y_i^k - b_i), \\quad \\forall\\ i=1,\\cdots, n\\\\\n",
    "y_i^{k+1} &= [\\mathrm{Prox}_{\\alpha g}(z_1^{k+1},\\cdots, z_n^{k+1})]_{i} =z_i^{k+1} - \\alpha v^{k+1}, \\quad \\forall\\ i=1,\\cdots, n \\\\\n",
    "x_i^{k+1} &= B_i^{-1} y_i^{k+1}, \\quad \\forall\\ i=1,\\cdots, n\n",
    "\\end{align*}\n",
    "\n",
    "where \n",
    "$$v^{k+1} = \\frac{1}{n\\alpha^2}\\big(\\alpha(z^{k+1}_1 + \\cdots + z^{k+1}_n) - \\mathrm{Prox}_{n \\alpha^2 \\|\\cdot\\|_1}(\\alpha z^{k+1}_1 + \\cdots + \\alpha z^{k+1}_n)\\big) \\quad \\mbox{(Need Allreduce Communication)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T05:20:59.628432Z",
     "start_time": "2021-03-30T05:20:59.622147Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting PrimalDecompose.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile PrimalDecompose.py\n",
    " \n",
    "import bluefog.torch as bf\n",
    "import torch\n",
    "\n",
    "bf.init()\n",
    "# Make sure different agent has different random seed.\n",
    "torch.manual_seed(12345 * bf.rank())\n",
    "\n",
    "def generate_data(m, d):\n",
    "    A = torch.randn(m, d).to(torch.double)\n",
    "    B_inv = torch.randn(d, d).to(torch.double)\n",
    "    ns = 0.1*torch.randn(m, 1).to(torch.double)\n",
    "    x_o = torch.rand(d,1).to(torch.double)\n",
    "    b = A.mm(x_o) + ns\n",
    "    \n",
    "    return A, B_inv, b\n",
    "\n",
    "def soft_threshold(x, kappa):\n",
    "    \n",
    "    zeros = torch.zeros(d,1).to(torch.double)\n",
    "    x = torch.max(x - kappa, zeros)\n",
    "    x = torch.min(x + kappa, zeros)\n",
    "    \n",
    "    return x\n",
    "\n",
    "def check_opt_cond(y, A, B_inv, b, alpha):\n",
    "    \n",
    "    m, d = A.shape\n",
    "    n = bf.size()\n",
    "    C = A.mm(B_inv)\n",
    "    \n",
    "    # update z\n",
    "    grad_local = C.t().mm(C.mm(y) - b)\n",
    "    z = y - alpha*grad_local\n",
    "    z_bar = bf.allreduce(z)\n",
    "    z_sum = z_bar * n\n",
    "\n",
    "    # update v\n",
    "    v = (1/(n*alpha*alpha)) * (alpha*z_sum - soft_threshold(alpha*z_sum, n*alpha*alpha))\n",
    "\n",
    "    # update y\n",
    "    y_next = z - alpha*v\n",
    "    \n",
    "    # the norm of global gradient is expected to be 0 (optimality condition)\n",
    "    global_grad_norm = torch.norm((y - y_next), p=2)\n",
    "    print(\"[Primal Decomposition] Rank {}: optimality metric norm: {}\".format(bf.rank(), global_grad_norm))\n",
    "        \n",
    "    return\n",
    "\n",
    "def primal_decomposition(A, B_inv, b, maxite=5000, alpha=1e-1):\n",
    "\n",
    "    m, d = A.shape\n",
    "    n = bf.size()\n",
    "    C = A.mm(B_inv)\n",
    "    \n",
    "    y = torch.zeros(d, 1, dtype=torch.double)\n",
    "\n",
    "    for _ in range(maxite):\n",
    "        # update z\n",
    "        grad_local = C.t().mm(C.mm(y) - b)\n",
    "        z = y - alpha*grad_local\n",
    "        z_bar = bf.allreduce(z)\n",
    "        z_sum = z_bar * n\n",
    "        \n",
    "        # update v\n",
    "        v = (1/(n*alpha*alpha)) * (alpha*z_sum - soft_threshold(alpha*z_sum, n*alpha*alpha))\n",
    "        \n",
    "        # update y\n",
    "        y = z - alpha*v\n",
    "\n",
    "        # update x\n",
    "        x = B_inv.mm(y)\n",
    "\n",
    "    check_opt_cond(y, A, B_inv, b, alpha)\n",
    "    \n",
    "    return y\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    m, d = 20, 5 # dimension of A\n",
    "    A, B_inv, b = generate_data(m, d)\n",
    "    y = primal_decomposition(A, B_inv, b, maxite=10000, alpha=3e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define $G^k_i = \\frac{1}{\\alpha}\\big(y_i^k - [\\mathrm{Prox}_{\\alpha g}(z_1^{k+1},\\cdots, z_n^{k+1})]_i\\big)$ and use $\\|G^k_i\\|$ as the metric to evaluate the optimality of $y_i^k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T05:21:15.021227Z",
     "start_time": "2021-03-30T05:21:00.552256Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Primal Decomposition] Rank 0: optimality metric norm: 3.359882887886575e-06\r\n",
      "[Primal Decomposition] Rank 1: optimality metric norm: 6.031938626839243e-06\r\n",
      "[Primal Decomposition] Rank 2: optimality metric norm: 9.928025440802728e-07\r\n",
      "[Primal Decomposition] Rank 3: optimality metric norm: 6.585390692784911e-06\r\n"
     ]
    }
   ],
   "source": [
    "! bfrun -np 4 python PrimalDecompose.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Distributed ADMM\n",
    "\n",
    "Suppose we want to optimize the following consensus problem:\n",
    "$$\n",
    "    \\min_{x} \\sum_{i=1}^n f_i(x)\n",
    "$$\n",
    "Each machine $i$ can access the function $f_i$ only. Note the problem has a shared $x$ cross all machines. To relax this condition, we can reformat the problem into the following equivalent form:\n",
    "\\begin{align}\n",
    "    \\min_{\\{x_i\\}, y} & \\;\\;\\; \\sum_{i=1}^n f_i(x_i),\\\\\n",
    "    {\\rm subject\\ to} & \\;\\;\\;  x_i = y,\\;\\; \\forall i. \n",
    "\\end{align}\n",
    "\n",
    "Applying ADMM, we obtain:\n",
    "\n",
    "\\begin{align}\n",
    "    x^{k+1}_i =&\\;\\; {\\rm argmin}_{x_{i}} \\left\\{ f_i(x_i) + \\langle u_i^k, x_i - y^k\\rangle + \\frac{\\alpha}{2}  \\left\\|x_i - y^k \\right\\|^2\\right\\} \\\\\n",
    "    y^{k+1} =&\\;\\; \\frac{1}{n} \\left(x_i^{k+1} + \\frac{1}{\\alpha} u^k_i\\right)\\\\\n",
    "    u^{k+1}_i = &\\;\\; u^k_i + \\alpha\\left(x_i^{k+1} - y^{k+1} \\right)\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further simplify it by noticing that $u^k_1,\\ldots,u^k_n$ has mean 0. Here we provide the code snippet of a simple quadratic cost function again. \n",
    "\n",
    "``` python\n",
    "# For each agent, it owns data A and b differently. \n",
    "def CentralizedADMMStepL2(A, b, x, y, u, alpha):\n",
    "    next_x = GradientStepL2(A, b, x, y, u, alpha)\n",
    "    # We use allreduce to mimic the centralized behavior\n",
    "    # It should be based on PS architecture and using gather and broadcast.\n",
    "    next_y = bf.allreduce(next_x)   # Without u is okay since allreudce(u) == 0\n",
    "    next_u = u + alpha * (next_x - next_y)\n",
    "    return next_x, next_y, next_u\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-30T05:21:17.723147Z",
     "start_time": "2021-03-30T05:21:15.026908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Centralized ADMM] Rank 0: ADMM residue gradient norm: 5.938006233263024e-15\r\n",
      "[Centralized ADMM] Rank 1: ADMM residue gradient norm: 5.938006233263024e-15\r\n",
      "[Centralized ADMM] Rank 2: ADMM residue gradient norm: 5.938006233263024e-15\r\n",
      "[Centralized ADMM] Rank 3: ADMM residue gradient norm: 5.938006233263024e-15\r\n",
      "Last three entries of x_ar:\r\n",
      " tensor([[0.6872],\r\n",
      "        [0.6552],\r\n",
      "        [0.8751]], dtype=torch.float64)\r\n",
      "Last three entries of x_admm:\r\n",
      " tensor([[0.6872],\r\n",
      "        [0.6552],\r\n",
      "        [0.8751]], dtype=torch.float64)\r\n"
     ]
    }
   ],
   "source": [
    "! bfrun -np 4 python CentralizedADMM.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the full code in the `CentralizedADMM.py`\n",
    "\n",
    "**Exercise**: Make modify the loss function, (sub-)gradient and proximal step for l1 + l2 cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
